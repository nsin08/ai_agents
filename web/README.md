# AI Agents Web Application

**Multi-Provider LLM Support | Chat Interface | API Key Management | Dynamic Model Selection**

## âœ… Current Features

âœ… **Chat Interface** - Real-time conversation with AI agents  
âœ… **6 LLM Providers** - Mock, Ollama, OpenAI (working) + Anthropic, Google, Azure (coming soon)  
âœ… **Dynamic Provider Selection** - Dropdown UI with status badges  
âœ… **API Key Management** - Secure input with validation  
âœ… **Model Selection** - Provider-specific model lists  
âœ… **Metadata Display** - Shows provider, model, and latency for each response  
âœ… **Response History** - Chat messages persist during session  

## Project Structure

```
web/
â”œâ”€â”€ frontend/                       # React 18 + TypeScript Application
â”‚   â”œâ”€â”€ package.json               # npm dependencies & scripts
â”‚   â”œâ”€â”€ tsconfig.json              # TypeScript strict configuration
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html             # HTML entry point
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ index.tsx              # React root
â”‚       â”œâ”€â”€ App.tsx                # Main App component
â”‚       â”œâ”€â”€ App.css                # Styles
â”‚       â”œâ”€â”€ index.css              # Global styles
â”‚       â”œâ”€â”€ setupTests.ts          # Jest configuration
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ Chat.tsx                  # Chat UI component
â”‚       â”‚   â”œâ”€â”€ Chat.css                  # Chat styles
â”‚       â”‚   â”œâ”€â”€ SettingsDrawer.tsx        # Provider selection UI
â”‚       â”‚   â”œâ”€â”€ SettingsDrawer.css        # Settings styles
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ chatService.js            # Backend API client
â”‚       â”‚   â”œâ”€â”€ chatService.d.ts          # TypeScript types
â”‚       â”‚   â””â”€â”€ providerService.ts        # Provider API client
â”‚       â””â”€â”€ types/
â”‚           â””â”€â”€ providers.ts              # Provider types
â”‚
â””â”€â”€ backend/                        # FastAPI Application
    â”œâ”€â”€ main.py                    # Entry point
    â”œâ”€â”€ config.py                  # Dependency injection
    â”œâ”€â”€ models.py                  # Pydantic data models
    â”œâ”€â”€ requirements.txt           # Python dependencies
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ chat.py                # Chat endpoints
    â”‚   â””â”€â”€ providers.py           # Provider endpoints
    â”œâ”€â”€ services/
    â”‚   â”œâ”€â”€ agent_labs_impl.py     # Business logic
    â”‚   â”œâ”€â”€ interfaces.py          # Service interfaces
    â”‚   â”œâ”€â”€ provider_service.py    # Provider service
    â”‚   â””â”€â”€ provider_factory.py    # Provider factory
    â””â”€â”€ tests/
        â”œâ”€â”€ test_api.py            # 8 endpoint tests âœ…
        â”œâ”€â”€ test_models.py         # 7 model tests âœ…
        â”œâ”€â”€ test_services.py       # 4 service tests âœ…
        â””â”€â”€ test_integration.py    # Integration tests âœ…
```

## Prerequisites

Before starting, ensure you have:
- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **Node.js 16+** with npm ([Download](https://nodejs.org/))
- **Git** (for cloning this repo)
- **(Optional) Ollama** for local LLM inference ([Download](https://ollama.ai/)) - only if using Ollama provider

## First-Time Setup (Run Once)

From the **root project directory** (`ai_agents/`):

```bash
# Install backend dependencies
cd web/backend
pip install -r requirements.txt

# Install frontend dependencies
cd web/frontend
npm install --legacy-peer-deps
```

## Quick Start (Run Every Time)

**You need TWO separate terminal windows:**

### Terminal 1: Start Backend
```bash
cd web/backend
python main.py
```
âœ… You should see: `âœ… Agent Chat API Started Successfully!`  
âœ… API Documentation: http://localhost:8000/docs  
âœ… Ready when backend is running

### Terminal 2: Start Frontend
```bash
cd web/frontend
npm start
```
âœ… You should see: `Compiled successfully!`  
âœ… Browser opens automatically at: http://localhost:3000  
âœ… If not, open http://localhost:3000 manually

## ğŸ® Using the Application

### First Time? Start with Mock Provider âœ…

1. **Open the app** at http://localhost:3000 (frontend should open automatically)
2. Type a message: `"Hello, what is Python?"`
3. Click **Send** - you'll get a response instantly
4. Look at the top-right for the **provider badge** (should show "Mock")

### Switching Providers

1. Click **âš™ï¸ Settings** button (top-right corner)
2. Select provider from **"Provider"** dropdown:
   - **Mock** âœ… - No setup, instant responses (start here!)
   - **Ollama** âœ… - Local models, free, private (requires running Ollama)
   - **OpenAI** âœ… - GPT-4, high quality (requires API key)
   - **Anthropic** ğŸš§ - Coming soon
   - **Google** ğŸš§ - Coming soon
   - **Azure OpenAI** ğŸš§ - Coming soon
3. Select **"Model"** from second dropdown
4. If using **OpenAI**: Paste your API key in the text field, click **Validate**
5. Click outside Settings or start chatting

### Using Ollama (Optional)

If you want to use Ollama:

1. **Install Ollama** from https://ollama.ai/
2. **Run Ollama server** (open terminal and run):
   ```bash
   ollama serve
   ```
3. **Download a model** (in another terminal):
   ```bash
   ollama pull mistral
   ```
4. In the app: Select **Ollama** provider â†’ Select **mistral** model â†’ Chat
5. First response takes a few seconds to generate locally

### Using OpenAI (Optional)

If you want to use OpenAI:

1. **Get API key** from https://platform.openai.com/account/api-keys
2. In the app: Select **OpenAI** provider
3. Paste your API key, click **Validate** (optional step)
4. Select model (gpt-4, gpt-3.5-turbo, etc.)
5. Start chatting - responses are faster and higher quality than Mock

## â“ Troubleshooting

| Problem | Solution |
|---------|----------|
| **Backend won't start** | Make sure port 8000 is free: `lsof -i :8000` (Mac/Linux) or `netstat -ano \| findstr :8000` (Windows) |
| **Frontend shows errors** | Run `npm install --legacy-peer-deps` again in `web/frontend` |
| **"Cannot GET /" at localhost:3000** | Wait 30 seconds for React to compile, then refresh |
| **Ollama model not found** | Run `ollama pull mistral` before selecting Ollama provider |
| **OpenAI API key rejected** | Check key is correct, test at https://platform.openai.com/account/api-keys |
| **Backend returns 500 error** | Check terminal 1 (backend) for error message - copy it here for help |
| **Frontend freezes on send** | Check backend is running (should see output in Terminal 1) |

## Environment Variables (Optional)

Create `web/backend/.env` to set defaults (not needed for Mock provider):

```env
# For OpenAI
OPENAI_API_KEY=sk-your-key-here

# For Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
```

No `.env` needed to get started with Mock provider!

## API Endpoints

### Chat Endpoints
- `POST /api/chat/sessions` - Create new chat session
- `POST /api/chat/send` - Send message to agent
- `GET /api/chat/sessions/{id}` - Get session history
- `GET /health` - Health check

### Provider Endpoints
- `GET /providers` - List all providers with metadata
- `GET /providers?include_models=true` - List providers with available models
- `POST /providers/validate` - Validate API key format

## Tech Stack

**Frontend:**
- React 18.2.0
- TypeScript 5.9.3
- react-scripts 5.0.1
- Testing Library + Jest

**Backend:**
- Python 3.14.2
- FastAPI 0.109.0
- Pydantic 2.12.5
- Uvicorn (ASGI server)
- pytest 9.0.2

**Agent Framework:**
- agent_labs (local package)
- Providers: MockProvider, OllamaProvider, OpenAIProvider

## Implementation Details

**Architecture:**
- Multi-provider support with factory pattern
- Dynamic provider instantiation
- Type-safe TypeScript frontend and Pydantic backend
- Async/await throughout for responsiveness
- Comprehensive error handling and validation

**What Works:**
- 3/6 providers fully functional (Mock, Ollama, OpenAI)
- Provider selection with beautiful gradient UI
- Dynamic model loading per provider
- API key validation and management
- Real-time chat interface
- Response metadata (provider, model, latency)

**Known Limitations:**
- Anthropic, Google, Azure providers not yet implemented
- API key validation is format-only (not live API test)
- Session persistence is in-memory only
- No frontend component tests yet

**Future Roadmap:**
- [ ] Implement remaining providers (Anthropic, Google, Azure)
- [ ] Live API key validation
- [ ] Frontend component tests
- [ ] Database-backed session persistence
- [ ] Conversation export/import
- [ ] User authentication
- [ ] Usage analytics

## Current Status âœ…

| Component | Status |
|-----------|--------|
| **Backend Tests** | âœ… 19/19 PASSING |
| **Integration Tests** | âœ… ALL PASSING |
| **Frontend Build** | âœ… COMPILING (0 errors) |
| **API Endpoints** | âœ… WORKING |
| **TypeScript** | âœ… STRICT MODE |
| **Chat Interface** | âœ… FULLY FUNCTIONAL |
| **Multi-Provider Support** | âœ… FULLY FUNCTIONAL |  
