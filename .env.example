# AI Agents - Environment Configuration
# Copy this file to .env and fill in your values
# Never commit .env to version control!

# ==============================================================================
# LLM PROVIDER CONFIGURATION
# ==============================================================================

# Provider Selection (REQUIRED)
# Options: mock, ollama, openai, anthropic, google, azure-openai
# Default: mock (for testing)
LLM_PROVIDER=mock

# Generic Model Configuration (optional if provider-specific set)
# Can be overridden by provider-specific MODEL variables below
# LLM_MODEL=gpt-4

# Generic Timeouts and Parameters (optional)
# LLM_TIMEOUT=60
# LLM_TEMPERATURE=0.7

# ==============================================================================
# MOCK PROVIDER (for testing/CI)
# ==============================================================================
# No authentication required
# MOCK_MODEL=mock-gpt-4

# ==============================================================================
# OLLAMA PROVIDER (local LLM)
# ==============================================================================
# Requires Ollama running locally: https://ollama.ai/
# Start with: ollama serve

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_TIMEOUT=60
OLLAMA_TEMPERATURE=0.7

# Available models (run: ollama list)
# - llama2 (7B, general purpose)
# - mistral:7b (7B, fast and capable)
# - llama2:13b (13B, more capable)
# - neural-chat (specialized for conversation)
# - qwen (multilingual)
# - gemma (Google's open model)

# ==============================================================================
# OPENAI PROVIDER
# ==============================================================================
# Get API key from: https://platform.openai.com/api-keys

# OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
# OPENAI_MODEL=gpt-4
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_TIMEOUT=30
# OPENAI_TEMPERATURE=0.7

# Available models:
# - gpt-4 (most capable, expensive)
# - gpt-4-turbo (faster, cheaper than gpt-4)
# - gpt-3.5-turbo (fast, affordable)

# ==============================================================================
# ANTHROPIC PROVIDER (Claude)
# ==============================================================================
# Get API key from: https://console.anthropic.com/

# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
# ANTHROPIC_TIMEOUT=30
# ANTHROPIC_TEMPERATURE=0.7

# Available models:
# - claude-3-opus-20240229 (most capable)
# - claude-3-sonnet-20240229 (balanced)
# - claude-3-haiku-20240307 (fast, affordable)

# ==============================================================================
# GOOGLE AI PROVIDER (Gemini)
# ==============================================================================
# Get API key from: https://makersuite.google.com/app/apikey

# GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxx
# GOOGLE_MODEL=gemini-pro
# GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1
# GOOGLE_TIMEOUT=30
# GOOGLE_TEMPERATURE=0.7

# Available models:
# - gemini-pro (general purpose)
# - gemini-pro-vision (multimodal)

# ==============================================================================
# AZURE OPENAI PROVIDER
# ==============================================================================
# Get credentials from Azure Portal

# AZURE_OPENAI_API_KEY=xxxxxxxxxxxxx
# AZURE_OPENAI_MODEL=gpt-4
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/
# AZURE_OPENAI_TIMEOUT=30
# AZURE_OPENAI_TEMPERATURE=0.7

# ==============================================================================
# AGENT CONFIGURATION
# ==============================================================================

# Maximum number of reasoning turns before stopping
AGENT_MAX_TURNS=10

# Agent execution timeout (seconds)
AGENT_TIMEOUT=300

# ==============================================================================
# TOOL CONFIGURATION
# ==============================================================================

# Tool execution timeout (seconds)
TOOL_TIMEOUT=30

# Temperature for tool-based LLM calls (lower = more deterministic)
TOOL_TEMPERATURE=0.3

# Maximum length for tool outputs (characters)
TOOL_MAX_LENGTH=500

# ==============================================================================
# TESTING CONFIGURATION
# ==============================================================================

# Enable Ollama integration tests (requires Ollama running)
# RUN_OLLAMA_TESTS=false

# ==============================================================================
# SECURITY NOTES
# ==============================================================================

# 1. NEVER commit .env file to version control
# 2. Add .env to .gitignore (already done)
# 3. Use different API keys for dev/staging/production
# 4. Rotate API keys regularly
# 5. Use secret management in production (AWS Secrets Manager, Azure Key Vault, etc.)
# 6. Monitor API usage and set billing alerts
# 7. Use environment-specific .env files (.env.dev, .env.prod, etc.)

# ==============================================================================
# EXAMPLES BY USE CASE
# ==============================================================================

# Example 1: Local Development with Ollama
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama2
# OLLAMA_BASE_URL=http://localhost:11434

# Example 2: CI/CD Testing (No LLM required)
# LLM_PROVIDER=mock
# MOCK_MODEL=mock-gpt-4

# Example 3: Production with OpenAI
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
# OPENAI_MODEL=gpt-4-turbo
# AGENT_MAX_TURNS=20
# AGENT_TIMEOUT=600

# Example 4: Multi-Provider Testing
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
